{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "initial_id",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-05-23T16:36:20.624507Z",
     "start_time": "2024-05-23T16:36:20.619934Z"
    }
   },
   "source": [
    "import os\n",
    "import cv2\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from skimage import color\n",
    "from scipy.ndimage import binary_fill_holes\n",
    "from skimage.segmentation import slic\n",
    "import networkx as nx\n",
    "\n",
    "from src.utils import load_image, downscale\n",
    "from src.depth import estimate_depth, normalize_depth\n",
    "\n",
    "from src.segmentation import SegmentModel, obtain_all_objects, fill_with_superpixels, show_layers\n",
    "from src.kmeans import get_optimal_k, assign2layers_kmeans\n",
    "\n",
    "from scipy.ndimage import binary_fill_holes\n",
    "# from src.graph import RAG, merge_regions_until_done"
   ],
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "23cceb53-1cd8-4e25-88df-7568528f1dbc",
   "metadata": {},
   "source": [
    "img_name = \"snowmountain\"\n",
    "ext = \".JPG\"\n",
    "\n",
    "orig_img = load_image(\"dataset/\" + img_name + ext)\n",
    "\n",
    "depth = normalize_depth(estimate_depth(orig_img)) * 100\n",
    "img = downscale(orig_img, *depth.shape)\n",
    "rgb_slic = slic(img, n_segments=1000, start_label=1, slic_zero=True)\n",
    "\n",
    "cie_img = color.rgb2lab(img)\n",
    "\n",
    "# plt.figure(figsize=(22,12))\n",
    "# \n",
    "# plt.subplot(121)\n",
    "# plt.title('Input Image')\n",
    "# plt.imshow(img)\n",
    "# \n",
    "# plt.subplot(122)\n",
    "# plt.title('Predicted Depth')\n",
    "# plt.imshow(depth)\n",
    "# \n",
    "# plt.colorbar(cax = plt.axes([0.91, 0.3, 0.01, 0.4]))\n",
    "#\n",
    "# plt.imshow(color.label2rgb(rgb_slic, img, kind='avg', bg_label=0))"
   ],
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "74d1f582165d7b96",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-05-23T16:50:38.992004Z",
     "start_time": "2024-05-23T16:50:38.136420Z"
    }
   },
   "source": [
    "mask_generator = SegmentModel(points_per_side=40).segment_anything \n",
    "object_masks = obtain_all_objects(mask_generator, img, img_r_thrd=0.95, n_thrd=10, ovlp_r_thrd=0.05, small_thrd=500) \n",
    "\n",
    "optimal_k = get_optimal_k(object_masks, depth)"
   ],
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "1d17c3af-3ea9-4318-a69d-3525a1eab262",
   "metadata": {},
   "source": [
    "masks = mask_generator.generate(img)\n",
    "# print(len(masks))\n",
    "print(len(object_masks))"
   ],
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "e67fc8ea-b262-470b-862f-ab3a60d94afa",
   "metadata": {},
   "source": [
    "# print(masks[1])\n",
    "n, m, d = img.shape\n",
    "\n",
    "final_mask = np.zeros((n, m), dtype=bool)\n",
    "\n",
    "# for msk in masks:\n",
    "for msk in object_masks:\n",
    "    # print(msk['stability_score'])\n",
    "    mask = msk['segmentation']\n",
    "    \n",
    "    image = np.zeros((n, m, d))\n",
    "    image[mask, :] = img[mask, :]\n",
    "    final_mask[mask] = True\n",
    "    # plt.imshow(image)\n",
    "    # plt.show()\n",
    "\n",
    "plt.imshow(final_mask)\n",
    "plt.colorbar()"
   ],
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "41d1f3c8-5fc3-41ed-a647-4fb3ed9eca78",
   "metadata": {},
   "source": [
    "print(len(object_masks))"
   ],
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "34681367bf295e58",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-05-23T16:50:42.113930Z",
     "start_time": "2024-05-23T16:50:38.993408Z"
    }
   },
   "source": [
    "# rag = RAG(img, depth, rgb_slic, object_masks)\n",
    "\n",
    "# g, regions = merge_regions_until_done(rag.graph, rag.edge_nodes, optimal_k)\n",
    "\n",
    "# for i, reg in enumerate(regions):\n",
    "#     plt.subplot(231 + i)\n",
    "\n",
    "#     mask = binary_fill_holes(g.nodes[reg]['mask'])\n",
    "#     image = np.zeros(img.shape)\n",
    "#     image[mask] = img[mask]\n",
    "\n",
    "#     plt.imshow(image)"
   ],
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "id": "2d3a0ead-c673-44a0-8153-ae40458fafd2",
   "metadata": {},
   "source": [
    "# TODO\n",
    "use two graphs: one to store the original superpixel information and the other to store the merged superpixels (then base the loss off of the original superpixel info)\n",
    "\n",
    "then also consider object masks when performing the segmentaion (instead of using differing colors as reason to avoid segmentation use similar color + same object to decrease loss (recall graph cuts))\n",
    "\n",
    "also use the depth information more (put a heavier weight to depth differences) (maybe perform histogram equalization?)\n",
    "\n",
    "use saliancy map to make a starting seed before going to edges and growing the edges\n",
    "\n",
    "delete inpaint from archive (the inpaint already in the archive) then move inpaint to archive (the one in project home)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "4ab89654-14ab-4186-bce2-e736afdd3d17",
   "metadata": {},
   "source": [
    "import networkx as nx\n",
    "from skimage import graph, color"
   ],
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "b03f1dfb-011c-4deb-9d5a-7801b1c80937",
   "metadata": {},
   "source": [
    "class RAG:\n",
    "    def __init__(self, img, depth, labels, objects):\n",
    "        \"\"\"\n",
    "        - img: input image\n",
    "        - depth: depth of the image\n",
    "        - labels: the result of slic (should start at 1)\n",
    "        \"\"\"\n",
    "        n, m = np.shape(depth)\n",
    "        cie_img = color.rgb2lab(img)\n",
    "\n",
    "        boundary_img = np.zeros((n + 10, m + 10, 3))\n",
    "        boundary_img[5:-5, 5:-5, :] = img\n",
    "\n",
    "        boundary_cie_img = np.zeros((n + 10, m + 10, 3))\n",
    "        boundary_cie_img[5:-5, 5:-5, :] = cie_img\n",
    "\n",
    "        boundary_depth = np.zeros((n + 10, m + 10))\n",
    "        boundary_depth[5:-5, 5:-5] = depth\n",
    "\n",
    "        # expand the superpixels to include a border of 0s\n",
    "        boundary_labels = np.zeros((n + 10, m + 10), dtype='int64')\n",
    "        boundary_labels[5:-5, 5:-5] = labels\n",
    "\n",
    "        g = graph.RAG(boundary_labels, connectivity=2)\n",
    "\n",
    "        for n in g:\n",
    "            g.nodes[n].update(\n",
    "                {\n",
    "                    'labels': [n],\n",
    "                    'mask': None,\n",
    "                    'pixel count': 0,\n",
    "                    'spixel count': 0,\n",
    "                    'total color': [],\n",
    "                    'total depth': [],\n",
    "                }\n",
    "            )\n",
    "\n",
    "        for index in np.ndindex(boundary_labels.shape):\n",
    "            current = boundary_labels[index]\n",
    "            g.nodes[current]['pixel count'] += 1\n",
    "            g.nodes[current]['total color'].append(boundary_cie_img[index])\n",
    "            g.nodes[current]['total depth'].append(boundary_depth[index])\n",
    "\n",
    "        for n in g:\n",
    "            g.nodes[n]['mask'] = labels == n\n",
    "            g.nodes[n]['spixel count'] = 1\n",
    "            g.nodes[n]['total color'] = np.array(g.nodes[n]['total color'], dtype='float64')\n",
    "            g.nodes[n]['total depth'] = np.array(g.nodes[n]['total depth'], dtype='float64')\n",
    "            g.nodes[n]['mean color'] = np.sum(g.nodes[n]['total color'] / g.nodes[n]['pixel count'], axis=0)\n",
    "            g.nodes[n]['mean depth'] = np.sum(g.nodes[n]['total depth'] / g.nodes[n]['pixel count'], axis=0)\n",
    "\n",
    "        for x, y, edge in g.edges(data=True):\n",
    "            # some kind of loss function with the distance, color difference, and segment anything result\n",
    "            edge['weight'] = (\n",
    "                color.deltaE_cie76(g.nodes[x]['mean color'], g.nodes[y]['mean color']) ** 2\n",
    "                + (g.nodes[x]['mean depth'] - g.nodes[y]['mean depth']) ** 2\n",
    "            )\n",
    "\n",
    "        self.boundary_graph = g.copy()\n",
    "        self.boundary_img = boundary_img\n",
    "        self.boundary_cie_img = boundary_cie_img\n",
    "        self.boundary_depth = boundary_depth\n",
    "        self.boundary_labels = boundary_labels\n",
    "\n",
    "        regions = []\n",
    "        for node in nx.all_neighbors(g, 0):\n",
    "            regions.append(node)\n",
    "\n",
    "        for n in regions:\n",
    "            g.remove_edge(n, 0)\n",
    "\n",
    "        g.remove_node(0)\n",
    "        \n",
    "        for obj in object_masks:\n",
    "            mask = obj['segmentation']\n",
    "\n",
    "            for n in g:\n",
    "                if np.count_nonzero(g.nodes[n]['mask'] & mask) / g.nodes[n]['pixel count'] > 0.8:\n",
    "                    for t in nx.all_neighbors(g, n):\n",
    "                        if n < t:\n",
    "                            # apply to each edge only once\n",
    "                            continue\n",
    "                            \n",
    "                        if np.count_nonzero(g.nodes[t]['mask'] & mask) / g.nodes[t]['pixel count'] > 0.8:\n",
    "                            g[n][t]['weight'] /= 5\n",
    "                            pass\n",
    "                            # (g.nodes[n]['mean depth'] - g.nodes[t]['mean depth']) ** 2\n",
    "\n",
    "        self.edge_nodes = regions\n",
    "        self.graph = g\n",
    "        self.img = img\n",
    "        self.cie_img = cie_img\n",
    "        self.depth = depth\n",
    "        self.labels = labels"
   ],
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "07d64e9d-d555-4529-ab2d-7403d712f3e0",
   "metadata": {},
   "source": [
    "def merge_nodes(g, n1, n2):\n",
    "    \"\"\"\n",
    "    merges the node n2 into the n1 while combining their pixel count, color, and depth into a single larger node\n",
    "    \"\"\"\n",
    "    g.remove_edge(n1, n2)\n",
    "\n",
    "    n1_con = []\n",
    "    for c in nx.all_neighbors(g, n1):\n",
    "        n1_con.append(c)\n",
    "    for c in n1_con:\n",
    "        g.remove_edge(n1, c)\n",
    "\n",
    "    n2_con = []\n",
    "    for c in nx.all_neighbors(g, n2):\n",
    "        n2_con.append(c)\n",
    "    for c in n2_con:\n",
    "        g.remove_edge(n2, c)\n",
    "\n",
    "    for n in np.unique(n1_con + n2_con):\n",
    "        g.add_edge(n1, n)\n",
    "        g[n1][n]['weight'] = (\n",
    "            # min(\n",
    "                color.deltaE_cie76(g.nodes[n1]['mean color'], g.nodes[n]['mean color']) ** 2\n",
    "            #     ,\n",
    "            #     color.deltaE_cie76(g.nodes[n1]['mean color'], g.nodes[n]['mean color']) ** 2)\n",
    "            # +\n",
    "            # min((g.nodes[n1]['mean depth'] - g.nodes[n]['mean depth']) ** 2,\n",
    "            #     (g.nodes[n2]['mean depth'] - g.nodes[n]['mean depth']) ** 2)\n",
    "        )\n",
    "\n",
    "    g.nodes[n1]['mask'] = np.logical_or(g.nodes[n1]['mask'], g.nodes[n2]['mask'])\n",
    "    \n",
    "    g.nodes[n1]['pixel count'] += g.nodes[n2]['pixel count']\n",
    "    g.nodes[n1]['total color'] = np.append(g.nodes[n1]['total color'], g.nodes[n2]['total color'], axis=0)\n",
    "    \n",
    "    g.nodes[n1]['mean color'] = np.sum(g.nodes[n1]['total color'] / g.nodes[n1]['pixel count'], axis=0)\n",
    "    g.nodes[n1]['mean depth'] = np.sum(g.nodes[n1]['total depth'] / g.nodes[n1]['pixel count'], axis=0)\n",
    "\n",
    "    g.remove_node(n2)"
   ],
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "81ac2cb6-eef7-435a-9d9d-11b963eb8921",
   "metadata": {},
   "source": [
    "def merge_regions_until_done(g, start_regions, regions_left=4):\n",
    "    \"\"\"\n",
    "    - g: the graph\n",
    "    - start_regions: the start regions (usually the edge nodes)\n",
    "    - regions_left: the number of regions when merging stops\n",
    "    \"\"\"\n",
    "    g = g.copy()\n",
    "    regions = start_regions.copy()\n",
    "\n",
    "    while g.number_of_nodes() > regions_left:\n",
    "        cheapest_edge_val = np.inf\n",
    "        cheapest_edge = [0, 0]\n",
    "\n",
    "        for n1 in regions:\n",
    "            for n2 in nx.all_neighbors(g, n1):\n",
    "                dst =  15 * (g.nodes[n1]['mean depth'] - g.nodes[n2]['mean depth']) ** 2 +\\\n",
    "                            (g.nodes[n1]['pixel count'] + g.nodes[n2]['pixel count']) + g[n1][n2]['weight']\n",
    "                if dst < cheapest_edge_val:\n",
    "                    cheapest_edge_val = dst\n",
    "                    cheapest_edge = [n1, n2]\n",
    "\n",
    "        n1 = cheapest_edge[0]\n",
    "        n2 = cheapest_edge[1]\n",
    "        merge_nodes(g, n1, n2)\n",
    "        if n2 in regions:\n",
    "            regions.remove(n2)\n",
    "\n",
    "    return g, regions"
   ],
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "f4e7ccc6-526d-4e41-9e24-7ef6cf39f329",
   "metadata": {},
   "source": [
    "rag = RAG(img, depth, rgb_slic, object_masks)\n",
    "\n",
    "g, regions = merge_regions_until_done(rag.graph, rag.edge_nodes, optimal_k)\n",
    "\n",
    "for i, reg in enumerate(regions):\n",
    "    plt.subplot(231 + i)\n",
    "\n",
    "    mask = binary_fill_holes(g.nodes[reg]['mask'])\n",
    "    image = np.zeros(img.shape)\n",
    "    image[mask] = img[mask]\n",
    "\n",
    "    plt.imshow(image)"
   ],
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "6cf2606e-639c-4275-900f-67a658509b0e",
   "metadata": {},
   "source": [
    "plt.figure(figsize=(30, 20))\n",
    "lc = graph.show_rag(rag.labels, rag.graph, rag.img)\n",
    "plt.colorbar(lc)"
   ],
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "7b483f72-b9d4-470f-a601-90c0a5aef594",
   "metadata": {},
   "source": [
    "from scipy.cluster.hierarchy import DisjointSet"
   ],
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "30d247fb-bfd5-4acd-b590-6ef039cc6033",
   "metadata": {},
   "source": [
    "g = rag.graph.copy()\n",
    "ds = DisjointSet(g.nodes())\n",
    "active = rag.edge_nodes.copy()\n",
    "\n",
    "while len(ds.subsets()) > 4:\n",
    "    cheapest_edge_val = np.inf\n",
    "    cheapest_edge = [0, 0]\n",
    "\n",
    "    # active nodes don't have attachments to interior nodes\n",
    "    for n1 in active:\n",
    "        for n2 in nx.all_neighbors(g, n1):\n",
    "            # dst =  15 * (g.nodes[n1]['mean depth'] - g.nodes[n2]['mean depth']) ** 2 +\\\n",
    "            #             (g.nodes[n1]['pixel count'] + g.nodes[n2]['pixel count']) + g[n1][n2]['weight']\n",
    "            dst = g[n1][n2]['weight'] + (g.nodes[n1]['spixel count'] + g.nodes[n2]['spixel count']) * 40\n",
    "            if dst < cheapest_edge_val:\n",
    "                cheapest_edge_val = dst\n",
    "                cheapest_edge = [n1, n2]\n",
    "\n",
    "    n1 = cheapest_edge[0]\n",
    "    n2 = cheapest_edge[1]\n",
    "\n",
    "    ds.merge(n1, n2)\n",
    "    new_spixel_count = g.nodes[n1]['spixel count'] + g.nodes[n2]['spixel count']\n",
    "    \n",
    "    ds_sub = ds.subset(n1)\n",
    "    for n in ds_sub:\n",
    "        g.nodes[n]['spixel count'] = new_spixel_count\n",
    "        if n not in active:\n",
    "            active.append(n)\n",
    "            \n",
    "        n_internal_con = []\n",
    "        for t in nx.all_neighbors(g, n):\n",
    "            if t in ds_sub:\n",
    "                n_internal_con.append(t)\n",
    "                \n",
    "        for t in n_internal_con:\n",
    "            g.remove_edge(n, t)"
   ],
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "68eb5e8a-fea5-4092-9070-f736801c1c40",
   "metadata": {},
   "source": [
    "plt.figure(figsize=(16,10))\n",
    "n, m, d = img.shape\n",
    "\n",
    "for i, s in enumerate(ds.subsets()):\n",
    "    plt.subplot(231 + i)\n",
    "\n",
    "    # print(s)\n",
    "    mask = np.zeros((n, m), dtype=bool)\n",
    "    for no in s:\n",
    "        mask[g.nodes[no]['mask']] = True\n",
    "    # binary_fill_holes()\n",
    "    image = np.zeros((n, m, 4))\n",
    "    image[mask, 3] = 1\n",
    "    image[mask, 0:3] = img[mask]\n",
    "\n",
    "    plt.imshow(image)"
   ],
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "id": "f5c2dd97-0505-4810-b6a8-acbe0684708e",
   "metadata": {},
   "source": [
    "# Save"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "7f814301e3070120",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-05-23T16:50:45.010081Z",
     "start_time": "2024-05-23T16:50:43.765178Z"
    }
   },
   "source": [
    "# n, m = np.shape(depth)\n",
    "\n",
    "# print(g)\n",
    "# print(regions)\n",
    "# # print(img.dtype)\n",
    "# # print(np.min(img * 255), np.max(img * 255))\n",
    "\n",
    "# masks = []\n",
    "# images = []\n",
    "\n",
    "# plt.figure(figsize=(16, 16))\n",
    "\n",
    "# for i, reg in enumerate(regions):\n",
    "#     plt.subplot(231 + i)\n",
    "    \n",
    "#     mask = g.nodes[reg]['mask']\n",
    "#     mask = binary_fill_holes(mask)\n",
    "#     masks.append(mask)\n",
    "\n",
    "#     # image with alpha channel\n",
    "#     image = np.zeros((n, m, 4), dtype=np.uint8)\n",
    "#     image[mask, 0:3] = img[mask] * 255.0\n",
    "#     image[mask, 3] = 255\n",
    "#     images.append(image)\n",
    "    \n",
    "#     plt.imshow(image)"
   ],
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "c86078c2f40a0104",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-05-23T16:50:45.217070Z",
     "start_time": "2024-05-23T16:50:45.011288Z"
    }
   },
   "source": [
    "# output_dir = \"output2/\"\n",
    "# output_dir = os.path.join(output_dir, img_name + '/')\n",
    "\n",
    "# if not os.path.exists(output_dir):\n",
    "#     os.makedirs(output_dir)\n",
    "\n",
    "#     cv2.imwrite(output_dir + img_name + '.png',\n",
    "#                 cv2.cvtColor(np.array(img * 255.0, dtype=np.uint8), cv2.COLOR_RGB2BGR))\n",
    "    \n",
    "#     for i, mask in enumerate(masks):\n",
    "#         np.save(output_dir + 'mask_' + str(i+1) + '.npy', mask)\n",
    "\n",
    "#     for i, image in enumerate(images):\n",
    "#         cv2.imwrite(output_dir + 'transparent_' + str(i+1) + '.png', cv2.cvtColor(image, cv2.COLOR_RGBA2BGRA))\n",
    "        \n",
    "#     for i, image in enumerate(images):\n",
    "#         cv2.imwrite(output_dir + 'layer_' + str(i+1) + '.png', cv2.cvtColor(image, cv2.COLOR_RGBA2BGR))"
   ],
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "id": "e66ce2c391f58a4",
   "metadata": {},
   "source": [
    "# Testing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "7f7af2e1-a421-4ea4-bc6a-72bfc78062ab",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-05-23T16:36:43.856894Z",
     "start_time": "2024-05-23T16:36:43.854277Z"
    }
   },
   "source": [
    "# object_masks = obtain_all_objects(get_msk_gen(), img)\n",
    "# check_overlapping(object_masks)"
   ],
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "d8d4328c-c552-4917-b074-b48d0c028ffe",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-05-23T16:36:43.862171Z",
     "start_time": "2024-05-23T16:36:43.859652Z"
    }
   },
   "source": [
    "# show_all_segmts_ind(object_masks, img)"
   ],
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "b0cadd51-cc2a-4f24-b724-026a9fbd03a6",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-05-23T16:36:43.868666Z",
     "start_time": "2024-05-23T16:36:43.863250Z"
    }
   },
   "source": [
    "# layers_idx, layers = assign2layers_kmeans(object_masks, depth, 3)\n",
    "# save_layers(img, object_masks, layers_idx, ['/tmp/layer1.png','/tmp/layer2.png','/tmp/layer3.png'])"
   ],
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "7da933f9-6c22-47fa-b87e-2be9d3205a76",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-05-23T16:36:43.874923Z",
     "start_time": "2024-05-23T16:36:43.869739Z"
    }
   },
   "source": [
    "# n, m = np.shape(depth)\n",
    "# segment_ids = np.unique(rgb_slic)\n",
    "# \n",
    "# masks = np.array([(rgb_slic == i) for i in segment_ids])\n",
    "# d_avgs = np.zeros((n, m), dtype='float')\n",
    "# for mk in masks:\n",
    "#     d_avgs[mk] = np.mean(depth[mk])\n",
    "# \n",
    "# plt.imshow(d_avgs)"
   ],
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "47e6ed77-6f64-4d7d-bc9e-822f5ebd969b",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-05-23T16:36:43.880599Z",
     "start_time": "2024-05-23T16:36:43.876038Z"
    }
   },
   "source": [
    "# # while this works I need to change the implementation a little bit to get edges and to change the loss function used\n",
    "# \n",
    "# g = graph.rag_mean_color(img, rgb_slic)\n",
    "# \n",
    "# # g = graph.rag_mean_color(depth, rgb_slic, mode='similarity')\n",
    "# # g = graph.rag_mean_color(depth, rgb_slic)\n",
    "# lc = graph.show_rag(rgb_slic, g, img)\n",
    "# plt.colorbar(lc)"
   ],
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "54fa349c-22b7-4d88-b5d8-4c8893e0e702",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-05-23T16:36:43.889167Z",
     "start_time": "2024-05-23T16:36:43.882391Z"
    }
   },
   "source": [
    "# n, m = np.shape(depth)\n",
    "# \n",
    "# boundary_slic = np.zeros((n + 10, m + 10), dtype='int64')\n",
    "# boundary_slic[5:-5,5:-5] = rgb_slic\n",
    "# \n",
    "# boundary_depth = np.zeros((n + 10, m + 10))\n",
    "# boundary_depth[5:-5,5:-5] = depth\n",
    "# \n",
    "# boundary_cie_img = np.zeros((n + 10, m + 10, 3))\n",
    "# boundary_cie_img[5:-5,5:-5,:] = cie_img\n",
    "# \n",
    "# boundary_img = np.zeros((n + 10, m + 10, 3))\n",
    "# boundary_img[5:-5,5:-5,:] = img\n",
    "# \n",
    "# plt.imshow(boundary_slic)\n",
    "# plt.colorbar()"
   ],
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "2d706dc3fa4bd32f",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-05-23T16:36:43.894715Z",
     "start_time": "2024-05-23T16:36:43.890457Z"
    }
   },
   "source": [
    "## from tunnel_book.RAG import RAG\n",
    "## \n",
    "## rag = RAG(img, depth, rgb_slic)"
   ],
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "bc8d80b0-3eeb-4d8c-b951-58c5e97ede1f",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-05-23T16:36:43.902686Z",
     "start_time": "2024-05-23T16:36:43.896818Z"
    }
   },
   "source": [
    "# sigma_c = 256\n",
    "# sigma_d = 100\n",
    "# \n",
    "# g = graph.RAG(boundary_slic, connectivity=2)\n",
    "# \n",
    "# for n in g:\n",
    "#     g.nodes[n].update(\n",
    "#         {\n",
    "#             'labels': [n],\n",
    "#             'mask': None,\n",
    "#             'pixel count': 0,\n",
    "#             'total color': [],\n",
    "#             'total depth': [],\n",
    "#         }\n",
    "#     )\n",
    "# \n",
    "# for index in np.ndindex(boundary_slic.shape):\n",
    "#     current = boundary_slic[index]\n",
    "#     g.nodes[current]['pixel count'] += 1\n",
    "#     g.nodes[current]['total color'].append(boundary_cie_img[index])\n",
    "#     g.nodes[current]['total depth'].append(boundary_depth[index])\n",
    "# \n",
    "# for n in g:\n",
    "#     g.nodes[n]['mask'] = rgb_slic == n\n",
    "#     g.nodes[n]['total color'] = np.array(g.nodes[n]['total color'], dtype='float64')\n",
    "#     g.nodes[n]['total depth'] = np.array(g.nodes[n]['total depth'], dtype='float64')\n",
    "#     g.nodes[n]['mean color'] = np.sum(g.nodes[n]['total color'] / g.nodes[n]['pixel count'], axis=0)\n",
    "#     g.nodes[n]['mean depth'] = np.sum(g.nodes[n]['total depth'] / g.nodes[n]['pixel count'], axis=0)\n",
    "# \n",
    "# for x, y, edge in g.edges(data=True):\n",
    "#     # some kind of loss function with the distance, color difference, and segment anything result\n",
    "#     edge['weight'] = (\n",
    "#         color.deltaE_cie76(g.nodes[x]['mean color'], g.nodes[y]['mean color']) ** 2\n",
    "#         # abs(g.nodes[x]['mean depth'] - g.nodes[y]['mean depth'])\n",
    "#     )\n",
    "#     # we will consider weight when we are actually collecting the superpixels into regions\n",
    "#         # math.e ** (-(diff**2) / sigma)\n",
    "#         # np.exp(-np.sum((g.nodes[x]['mean color'] - g.nodes[y]['mean color']) ** 2) / (2 * (sigma_c ** 2)))  # increase weight for color similarity\n",
    "#         # *\n",
    "#         # np.exp(-np.sum((g.nodes[x]['mean depth'] - g.nodes[y]['mean depth']) ** 2) / (2 * (sigma_d ** 2)))  # increase weight for depth similarity\n",
    "\n",
    "    \n",
    "# lc = graph.show_rag(boundary_slic, g, boundary_img)\n",
    "## lc = graph.show_rag(rag.boundary_labels, rag.boundary_graph, rag.boundary_img)\n",
    "## plt.colorbar(lc)"
   ],
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "5b541bb6-63f8-47fa-9662-e0fa87b651f6",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-05-23T16:36:43.913775Z",
     "start_time": "2024-05-23T16:36:43.904018Z"
    }
   },
   "source": [
    "# regions = []\n",
    "# for node in nx.all_neighbors(g, 0):\n",
    "#     regions.append(node)\n",
    "#     \n",
    "# for n in regions:\n",
    "#     g.remove_edge(n, 0)\n",
    "# \n",
    "# g.remove_node(0)\n",
    "# \n",
    "# lc = graph.show_rag(rgb_slic, g, img)\n",
    "# lc = graph.show_rag(rgb_slic, g, img)\n",
    "\n",
    "## plt.figure(figsize=(30, 20))\n",
    "## lc = graph.show_rag(rag.labels, rag.graph, rag.img)\n",
    "## plt.colorbar(lc)"
   ],
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "e70d4045-aacc-47a8-840c-ba62688e7114",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-05-23T16:36:43.923172Z",
     "start_time": "2024-05-23T16:36:43.915070Z"
    }
   },
   "source": [
    "# # maybe write a method for this block\n",
    "\n",
    "# g = rag.graph.copy()\n",
    "# regions = rag.edge_nodes.copy()\n",
    "# \n",
    "# while g.number_of_nodes() > 3:\n",
    "#     cheapest_edge_val = np.inf\n",
    "#     cheapest_edge = [0, 0]\n",
    "# \n",
    "#     for n1 in regions:\n",
    "#         for n2 in nx.all_neighbors(g, n1):\n",
    "#             dst = 15 * (g.nodes[n1]['mean depth'] - g.nodes[n2]['mean depth']) ** 2 + (g.nodes[n1]['pixel count'] + g.nodes[n2]['pixel count']) + g[n1][n2]['weight'] \n",
    "#             if dst < cheapest_edge_val:\n",
    "#                 cheapest_edge_val = dst\n",
    "#                 cheapest_edge = [n1, n2]\n",
    "# \n",
    "#     n1 = cheapest_edge[0]\n",
    "#     n2 = cheapest_edge[1]\n",
    "#     g.remove_edge(n1, n2)\n",
    "#     if n2 in regions:\n",
    "#         regions.remove(n2)\n",
    "# \n",
    "#     g.nodes[n1]['mask'] = np.logical_or(g.nodes[n1]['mask'], g.nodes[n2]['mask'])\n",
    "#     g.nodes[n1]['pixel count'] += g.nodes[n2]['pixel count']\n",
    "#     g.nodes[n1]['total color'] = np.append(g.nodes[n1]['total color'], g.nodes[n2]['total color'], axis=0)\n",
    "#     g.nodes[n1]['total depth'] = np.append(g.nodes[n1]['total depth'], g.nodes[n2]['total depth'], axis=0)\n",
    "#     g.nodes[n1]['mean color'] = np.sum(g.nodes[n1]['total color'] / g.nodes[n1]['pixel count'], axis=0)\n",
    "#     g.nodes[n1]['mean depth'] = np.sum(g.nodes[n1]['total depth'] / g.nodes[n1]['pixel count'], axis=0)\n",
    "#     \n",
    "#     n1_con = []\n",
    "#     for c in nx.all_neighbors(g, n1):\n",
    "#         n1_con.append(c)\n",
    "#     for c in n1_con:\n",
    "#         g.remove_edge(n1, c)\n",
    "# \n",
    "#     n2_con = []\n",
    "#     for c in nx.all_neighbors(g, n2):\n",
    "#         n2_con.append(c)\n",
    "#     for c in n2_con:\n",
    "#         g.remove_edge(n2, c)\n",
    "# \n",
    "#     for n in np.unique(n1_con + n2_con):\n",
    "#         g.add_edge(n1, n)\n",
    "#         g[n1][n]['weight'] = (\n",
    "#             color.deltaE_cie76(g.nodes[n1]['mean color'], g.nodes[n]['mean color'])\n",
    "#             # abs(g.nodes[x]['mean depth'] - g.nodes[y]['mean depth'])\n",
    "#         )\n",
    "# \n",
    "#     g.remove_node(n2)"
   ],
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "f38a5566-c49a-4d2b-9f30-d401f747408d",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-05-23T16:36:43.932343Z",
     "start_time": "2024-05-23T16:36:43.924557Z"
    }
   },
   "source": [
    "# n, m = np.shape(depth)\n",
    "# \n",
    "# print(g)\n",
    "# print(regions)\n",
    "# \n",
    "# masks = []\n",
    "# \n",
    "# plt.figure(figsize=(16,10))\n",
    "# for i, reg in enumerate(regions):\n",
    "#     plt.subplot(221 + i)\n",
    "#     res = np.zeros((n, m, 3))\n",
    "#     res[g.nodes[reg]['mask']] = img[g.nodes[reg]['mask']]\n",
    "#     masks.append(g.nodes[reg]['mask'])\n",
    "#     plt.imshow(res)\n",
    "#     \n",
    "# # print(g.nodes[1]['mask'].shape)\n",
    "# # print(res.shape)"
   ],
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "id": "373c4ede-3bfa-4e18-8399-841dbdac6e32",
   "metadata": {},
   "source": [
    "# TODO: keep the most salient objects together\n",
    "# TODO: should attempt to push the depth amount to ensure that the different layers have significant enough difference in depth\n",
    "# TODO: create a conda or pip env\n",
    "# TODO: difference in superpixels should be more than just difference in average color and depth (could also consider difference in texture, saliency, and objects)\n",
    "\n",
    "what does the edge weight mean?\n",
    "- at the moment the edge weight is based on the difference in color and depth between superpixels\n",
    "- this doesn't really make sense because a single object could be made from many colors\n",
    "    - what if we used the information from the segment anything to get the objects then use superpixels to get a better outline\n",
    "    - perform segment anything then find all the superpixels that fit inside the segments\n",
    "    - then for superpixels within a segment make the weights large (and use medium weights for when the color changes but still within same segment)\n",
    "\n",
    "large weights for parts to slice or small weights for parts to slice\n",
    "- small weights for the parts to slice\n",
    "- large weights for parts to keep together\n",
    "    - or small weights for parts to keep together\n",
    "    - small difference in depth to keep together\n",
    "- small dist for depth and color to keep together (choose the smallest disparity value to add)\n",
    "\n",
    "how do we also consider the depth of the object?\n",
    "- consider 4 (or as many layers as we want) clouds that are initialized to the kmeans averages for depths over the entire image\n",
    "- begin by taking the 4 points next to the edge with the nearest depth values\n",
    "- then we continusouly merge adjacent superpixels based on edge weight (the difference in color and segment anything result) and the difference in average depth for that superpixel\n",
    "- each time we can update the average depth for our cloud as use that updated depth when looking for the next superpixel\n",
    "\n",
    "instead of initalizing only 4 clouds we can allow all the edge nodes to be clouds and iterate until there are only 4 left"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "b533b310-a80e-43c6-a30f-108d36e73173",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-05-23T16:36:43.946735Z",
     "start_time": "2024-05-23T16:36:43.933470Z"
    }
   },
   "source": [
    "from src.saliency_map import FasaSaliencyMapping\n",
    "import cv2"
   ],
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "cea7dc7f270fe7d0",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-05-23T16:36:43.962424Z",
     "start_time": "2024-05-23T16:36:43.947775Z"
    }
   },
   "source": [
    "my_map = FasaSaliencyMapping(img.shape[0], img.shape[1])  # init the saliency object\n",
    "image_salient_1 = my_map.returnMask(color.rgb2lab(img), tot_bins=8, format='LAB')  # get the mask from the original image\n",
    "image_salient_1 = cv2.GaussianBlur(image_salient_1, (3,3), 1)  # applying gaussin blur to make it pretty\n",
    "\n",
    "print(image_salient_1.shape)\n",
    "plt.figure(figsize=(16,10))\n",
    "# plt.imshow(image_salient_1 > 50)\n",
    "plt.imshow(image_salient_1 < 50)\n",
    "# plt.imshow(np.exp(-image_salient_1/256))\n",
    "plt.colorbar()"
   ],
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "4509214fd4bae2e6",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-05-23T16:36:43.975039Z",
     "start_time": "2024-05-23T16:36:43.963515Z"
    }
   },
   "source": [
    "plt.figure(figsize=(16,10))\n",
    "plt.imshow(color.label2rgb(rgb_slic, image_salient_1, kind='avg', bg_label=0))\n",
    "plt.colorbar()"
   ],
   "outputs": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "tunnel-book2",
   "language": "python",
   "name": "tunnel-book2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
