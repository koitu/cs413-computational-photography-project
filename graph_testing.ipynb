{
 "cells": [
  {
   "cell_type": "code",
   "id": "initial_id",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-05-23T16:36:20.624507Z",
     "start_time": "2024-05-23T16:36:20.619934Z"
    }
   },
   "source": [
    "import os\n",
    "import cv2\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from src.depth import estimate_depth, normalize_depth\n",
    "from src.utils import load_image, downscale\n",
    "from src.graph import RAG\n",
    "\n",
    "from skimage import color\n",
    "from scipy.ndimage import binary_fill_holes\n",
    "from skimage.segmentation import slic\n",
    "import networkx as nx\n",
    "\n",
    "from sklearn.cluster import KMeans\n",
    "from yellowbrick.cluster import KElbowVisualizer\n",
    "\n",
    "# from skimage import segmentation, graph, color\n",
    "# from tunnel_book.segmentation import get_msk_gen\n",
    "# from tunnel_book.viz import show_anns, show_all_segmts_ind, save_layers\n",
    "# from tunnel_book.cut import assign2layers_kmeans\n",
    "# from tunnel_book.process_seg_img import obtain_all_objects, check_overlapping"
   ],
   "execution_count": 115,
   "outputs": []
  },
  {
   "cell_type": "code",
   "id": "ecbd7dcb06ee41e0",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-05-23T16:50:31.879838Z",
     "start_time": "2024-05-23T16:50:26.662862Z"
    }
   },
   "source": [
    "img_name = \"train\"\n",
    "ext = \".jpg\"\n",
    "\n",
    "img = load_image(\"dataset/\" + img_name + ext)\n",
    "\n",
    "depth = normalize_depth(estimate_depth(img)) * 100\n",
    "img = downscale(img, *depth.shape)\n",
    "cie_img = color.rgb2lab(img)\n",
    "\n",
    "# for some reason slic works best with rgb pixel values (probably using wrong dist metric in cie?)\n",
    "rgb_slic = slic(img, n_segments=1000, start_label=1, slic_zero=True)\n",
    "plt.imshow(color.label2rgb(rgb_slic, img, kind='avg', bg_label=0))"
   ],
   "execution_count": 197,
   "outputs": []
  },
  {
   "cell_type": "code",
   "id": "1431914c-1fdd-44ad-abc9-35f679edda18",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-05-23T16:50:38.134594Z",
     "start_time": "2024-05-23T16:50:38.132192Z"
    }
   },
   "source": [
    "# plt.figure(figsize=(22,12))\n",
    "# \n",
    "# plt.subplot(121)\n",
    "# plt.title('Input Image')\n",
    "# plt.imshow(img)\n",
    "# \n",
    "# plt.subplot(122)\n",
    "# plt.title('Predicted Depth')\n",
    "# plt.imshow(depth)\n",
    "# \n",
    "# plt.colorbar(cax = plt.axes([0.91, 0.3, 0.01, 0.4]))"
   ],
   "execution_count": 199,
   "outputs": []
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-05-23T16:50:38.992004Z",
     "start_time": "2024-05-23T16:50:38.136420Z"
    }
   },
   "cell_type": "code",
   "source": [
    "depth_features = np.array([[np.mean(depth[m == rgb_slic])] for m in np.unique(rgb_slic)])\n",
    "\n",
    "model = KMeans()\n",
    "visualizer = KElbowVisualizer(model, k=(2,20), metric='distortion', timings=True)\n",
    "visualizer.fit(depth_features)\n",
    "visualizer.show()\n",
    "\n",
    "# when the k value here is high the result is probably be bad\n",
    "optimalK = visualizer.elbow_value_\n",
    "print(f\"Optimal number of clusters: {optimalK}\")"
   ],
   "id": "74d1f582165d7b96",
   "execution_count": 200,
   "outputs": []
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-05-23T16:50:42.113930Z",
     "start_time": "2024-05-23T16:50:38.993408Z"
    }
   },
   "cell_type": "code",
   "source": "rag = RAG(img, depth, rgb_slic)",
   "id": "34681367bf295e58",
   "execution_count": 201,
   "outputs": []
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-05-23T16:50:43.763819Z",
     "start_time": "2024-05-23T16:50:42.115166Z"
    }
   },
   "cell_type": "code",
   "source": [
    "g = rag.graph.copy()\n",
    "regions = rag.edge_nodes.copy()\n",
    "\n",
    "while g.number_of_nodes() > optimalK:\n",
    "    cheapest_edge_val = np.inf\n",
    "    cheapest_edge = [0, 0]\n",
    "\n",
    "    for n1 in regions:\n",
    "        for n2 in nx.all_neighbors(g, n1):\n",
    "            dst = 15 * (g.nodes[n1]['mean depth'] - g.nodes[n2]['mean depth']) ** 2 + (\n",
    "                        g.nodes[n1]['pixel count'] + g.nodes[n2]['pixel count']) + g[n1][n2]['weight']\n",
    "            if dst < cheapest_edge_val:\n",
    "                cheapest_edge_val = dst\n",
    "                cheapest_edge = [n1, n2]\n",
    "\n",
    "    n1 = cheapest_edge[0]\n",
    "    n2 = cheapest_edge[1]\n",
    "    g.remove_edge(n1, n2)\n",
    "    if n2 in regions:\n",
    "        regions.remove(n2)\n",
    "\n",
    "    g.nodes[n1]['mask'] = np.logical_or(g.nodes[n1]['mask'], g.nodes[n2]['mask'])\n",
    "    g.nodes[n1]['pixel count'] += g.nodes[n2]['pixel count']\n",
    "    g.nodes[n1]['total color'] = np.append(g.nodes[n1]['total color'], g.nodes[n2]['total color'], axis=0)\n",
    "    g.nodes[n1]['total depth'] = np.append(g.nodes[n1]['total depth'], g.nodes[n2]['total depth'], axis=0)\n",
    "    g.nodes[n1]['mean color'] = np.sum(g.nodes[n1]['total color'] / g.nodes[n1]['pixel count'], axis=0)\n",
    "    g.nodes[n1]['mean depth'] = np.sum(g.nodes[n1]['total depth'] / g.nodes[n1]['pixel count'], axis=0)\n",
    "\n",
    "    n1_con = []\n",
    "    for c in nx.all_neighbors(g, n1):\n",
    "        n1_con.append(c)\n",
    "    for c in n1_con:\n",
    "        g.remove_edge(n1, c)\n",
    "\n",
    "    n2_con = []\n",
    "    for c in nx.all_neighbors(g, n2):\n",
    "        n2_con.append(c)\n",
    "    for c in n2_con:\n",
    "        g.remove_edge(n2, c)\n",
    "\n",
    "    for n in np.unique(n1_con + n2_con):\n",
    "        g.add_edge(n1, n)\n",
    "        g[n1][n]['weight'] = (\n",
    "            color.deltaE_cie76(g.nodes[n1]['mean color'], g.nodes[n]['mean color'])\n",
    "            # abs(g.nodes[x]['mean depth'] - g.nodes[y]['mean depth'])\n",
    "        )\n",
    "\n",
    "    g.remove_node(n2)"
   ],
   "id": "bd6e2b0e4646f3ae",
   "execution_count": 202,
   "outputs": []
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-05-23T16:50:45.010081Z",
     "start_time": "2024-05-23T16:50:43.765178Z"
    }
   },
   "cell_type": "code",
   "source": [
    "n, m = np.shape(depth)\n",
    "\n",
    "print(g)\n",
    "print(regions)\n",
    "# print(img.dtype)\n",
    "# print(np.min(img * 255), np.max(img * 255))\n",
    "\n",
    "masks = []\n",
    "images = []\n",
    "\n",
    "plt.figure(figsize=(16, 16))\n",
    "\n",
    "for i, reg in enumerate(regions):\n",
    "    plt.subplot(231 + i)\n",
    "    \n",
    "    mask = g.nodes[reg]['mask']\n",
    "    mask = binary_fill_holes(mask)\n",
    "    masks.append(mask)\n",
    "\n",
    "    # image with alpha channel\n",
    "    image = np.zeros((n, m, 4), dtype=np.uint8)\n",
    "    image[mask, 0:3] = img[mask] * 255.0\n",
    "    image[mask, 3] = 255\n",
    "    images.append(image)\n",
    "    \n",
    "    plt.imshow(image)"
   ],
   "id": "7f814301e3070120",
   "execution_count": 203,
   "outputs": []
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-05-23T16:50:45.217070Z",
     "start_time": "2024-05-23T16:50:45.011288Z"
    }
   },
   "cell_type": "code",
   "source": [
    "output_dir = \"output2/\"\n",
    "output_dir = os.path.join(output_dir, img_name + '/')\n",
    "\n",
    "if not os.path.exists(output_dir):\n",
    "    os.makedirs(output_dir)\n",
    "\n",
    "    cv2.imwrite(output_dir + img_name + '.png',\n",
    "                cv2.cvtColor(np.array(img * 255.0, dtype=np.uint8), cv2.COLOR_RGB2BGR))\n",
    "    \n",
    "    for i, mask in enumerate(masks):\n",
    "        np.save(output_dir + 'mask_' + str(i+1) + '.npy', mask)\n",
    "\n",
    "    for i, image in enumerate(images):\n",
    "        cv2.imwrite(output_dir + 'transparent_' + str(i+1) + '.png', cv2.cvtColor(image, cv2.COLOR_RGBA2BGRA))\n",
    "        \n",
    "    for i, image in enumerate(images):\n",
    "        cv2.imwrite(output_dir + 'layer_' + str(i+1) + '.png', cv2.cvtColor(image, cv2.COLOR_RGBA2BGR))"
   ],
   "id": "c86078c2f40a0104",
   "execution_count": 204,
   "outputs": []
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "# Testing",
   "id": "e66ce2c391f58a4"
  },
  {
   "cell_type": "code",
   "id": "7f7af2e1-a421-4ea4-bc6a-72bfc78062ab",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-05-23T16:36:43.856894Z",
     "start_time": "2024-05-23T16:36:43.854277Z"
    }
   },
   "source": [
    "# object_masks = obtain_all_objects(get_msk_gen(), img)\n",
    "# check_overlapping(object_masks)"
   ],
   "execution_count": 124,
   "outputs": []
  },
  {
   "cell_type": "code",
   "id": "d8d4328c-c552-4917-b074-b48d0c028ffe",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-05-23T16:36:43.862171Z",
     "start_time": "2024-05-23T16:36:43.859652Z"
    }
   },
   "source": "# show_all_segmts_ind(object_masks, img)",
   "execution_count": 125,
   "outputs": []
  },
  {
   "cell_type": "code",
   "id": "b0cadd51-cc2a-4f24-b724-026a9fbd03a6",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-05-23T16:36:43.868666Z",
     "start_time": "2024-05-23T16:36:43.863250Z"
    }
   },
   "source": [
    "# layers_idx, layers = assign2layers_kmeans(object_masks, depth, 3)\n",
    "# save_layers(img, object_masks, layers_idx, ['/tmp/layer1.png','/tmp/layer2.png','/tmp/layer3.png'])"
   ],
   "execution_count": 126,
   "outputs": []
  },
  {
   "cell_type": "code",
   "id": "7da933f9-6c22-47fa-b87e-2be9d3205a76",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-05-23T16:36:43.874923Z",
     "start_time": "2024-05-23T16:36:43.869739Z"
    }
   },
   "source": [
    "# n, m = np.shape(depth)\n",
    "# segment_ids = np.unique(rgb_slic)\n",
    "# \n",
    "# masks = np.array([(rgb_slic == i) for i in segment_ids])\n",
    "# d_avgs = np.zeros((n, m), dtype='float')\n",
    "# for mk in masks:\n",
    "#     d_avgs[mk] = np.mean(depth[mk])\n",
    "# \n",
    "# plt.imshow(d_avgs)"
   ],
   "execution_count": 127,
   "outputs": []
  },
  {
   "cell_type": "code",
   "id": "47e6ed77-6f64-4d7d-bc9e-822f5ebd969b",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-05-23T16:36:43.880599Z",
     "start_time": "2024-05-23T16:36:43.876038Z"
    }
   },
   "source": [
    "# # while this works I need to change the implementation a little bit to get edges and to change the loss function used\n",
    "# \n",
    "# g = graph.rag_mean_color(img, rgb_slic)\n",
    "# \n",
    "# # g = graph.rag_mean_color(depth, rgb_slic, mode='similarity')\n",
    "# # g = graph.rag_mean_color(depth, rgb_slic)\n",
    "# lc = graph.show_rag(rgb_slic, g, img)\n",
    "# plt.colorbar(lc)"
   ],
   "execution_count": 128,
   "outputs": []
  },
  {
   "cell_type": "code",
   "id": "54fa349c-22b7-4d88-b5d8-4c8893e0e702",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-05-23T16:36:43.889167Z",
     "start_time": "2024-05-23T16:36:43.882391Z"
    }
   },
   "source": [
    "# n, m = np.shape(depth)\n",
    "# \n",
    "# boundary_slic = np.zeros((n + 10, m + 10), dtype='int64')\n",
    "# boundary_slic[5:-5,5:-5] = rgb_slic\n",
    "# \n",
    "# boundary_depth = np.zeros((n + 10, m + 10))\n",
    "# boundary_depth[5:-5,5:-5] = depth\n",
    "# \n",
    "# boundary_cie_img = np.zeros((n + 10, m + 10, 3))\n",
    "# boundary_cie_img[5:-5,5:-5,:] = cie_img\n",
    "# \n",
    "# boundary_img = np.zeros((n + 10, m + 10, 3))\n",
    "# boundary_img[5:-5,5:-5,:] = img\n",
    "# \n",
    "# plt.imshow(boundary_slic)\n",
    "# plt.colorbar()"
   ],
   "execution_count": 129,
   "outputs": []
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-05-23T16:36:43.894715Z",
     "start_time": "2024-05-23T16:36:43.890457Z"
    }
   },
   "cell_type": "code",
   "source": [
    "## from tunnel_book.RAG import RAG\n",
    "## \n",
    "## rag = RAG(img, depth, rgb_slic)"
   ],
   "id": "2d706dc3fa4bd32f",
   "execution_count": 130,
   "outputs": []
  },
  {
   "cell_type": "code",
   "id": "bc8d80b0-3eeb-4d8c-b951-58c5e97ede1f",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-05-23T16:36:43.902686Z",
     "start_time": "2024-05-23T16:36:43.896818Z"
    }
   },
   "source": [
    "# sigma_c = 256\n",
    "# sigma_d = 100\n",
    "# \n",
    "# g = graph.RAG(boundary_slic, connectivity=2)\n",
    "# \n",
    "# for n in g:\n",
    "#     g.nodes[n].update(\n",
    "#         {\n",
    "#             'labels': [n],\n",
    "#             'mask': None,\n",
    "#             'pixel count': 0,\n",
    "#             'total color': [],\n",
    "#             'total depth': [],\n",
    "#         }\n",
    "#     )\n",
    "# \n",
    "# for index in np.ndindex(boundary_slic.shape):\n",
    "#     current = boundary_slic[index]\n",
    "#     g.nodes[current]['pixel count'] += 1\n",
    "#     g.nodes[current]['total color'].append(boundary_cie_img[index])\n",
    "#     g.nodes[current]['total depth'].append(boundary_depth[index])\n",
    "# \n",
    "# for n in g:\n",
    "#     g.nodes[n]['mask'] = rgb_slic == n\n",
    "#     g.nodes[n]['total color'] = np.array(g.nodes[n]['total color'], dtype='float64')\n",
    "#     g.nodes[n]['total depth'] = np.array(g.nodes[n]['total depth'], dtype='float64')\n",
    "#     g.nodes[n]['mean color'] = np.sum(g.nodes[n]['total color'] / g.nodes[n]['pixel count'], axis=0)\n",
    "#     g.nodes[n]['mean depth'] = np.sum(g.nodes[n]['total depth'] / g.nodes[n]['pixel count'], axis=0)\n",
    "# \n",
    "# for x, y, edge in g.edges(data=True):\n",
    "#     # some kind of loss function with the distance, color difference, and segment anything result\n",
    "#     edge['weight'] = (\n",
    "#         color.deltaE_cie76(g.nodes[x]['mean color'], g.nodes[y]['mean color']) ** 2\n",
    "#         # abs(g.nodes[x]['mean depth'] - g.nodes[y]['mean depth'])\n",
    "#     )\n",
    "#     # we will consider weight when we are actually collecting the superpixels into regions\n",
    "#         # math.e ** (-(diff**2) / sigma)\n",
    "#         # np.exp(-np.sum((g.nodes[x]['mean color'] - g.nodes[y]['mean color']) ** 2) / (2 * (sigma_c ** 2)))  # increase weight for color similarity\n",
    "#         # *\n",
    "#         # np.exp(-np.sum((g.nodes[x]['mean depth'] - g.nodes[y]['mean depth']) ** 2) / (2 * (sigma_d ** 2)))  # increase weight for depth similarity\n",
    "\n",
    "    \n",
    "# lc = graph.show_rag(boundary_slic, g, boundary_img)\n",
    "## lc = graph.show_rag(rag.boundary_labels, rag.boundary_graph, rag.boundary_img)\n",
    "## plt.colorbar(lc)"
   ],
   "execution_count": 131,
   "outputs": []
  },
  {
   "cell_type": "code",
   "id": "5b541bb6-63f8-47fa-9662-e0fa87b651f6",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-05-23T16:36:43.913775Z",
     "start_time": "2024-05-23T16:36:43.904018Z"
    }
   },
   "source": [
    "# regions = []\n",
    "# for node in nx.all_neighbors(g, 0):\n",
    "#     regions.append(node)\n",
    "#     \n",
    "# for n in regions:\n",
    "#     g.remove_edge(n, 0)\n",
    "# \n",
    "# g.remove_node(0)\n",
    "# \n",
    "# lc = graph.show_rag(rgb_slic, g, img)\n",
    "# lc = graph.show_rag(rgb_slic, g, img)\n",
    "\n",
    "## plt.figure(figsize=(30, 20))\n",
    "## lc = graph.show_rag(rag.labels, rag.graph, rag.img)\n",
    "## plt.colorbar(lc)"
   ],
   "execution_count": 132,
   "outputs": []
  },
  {
   "cell_type": "code",
   "id": "e70d4045-aacc-47a8-840c-ba62688e7114",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-05-23T16:36:43.923172Z",
     "start_time": "2024-05-23T16:36:43.915070Z"
    }
   },
   "source": [
    "# # maybe write a method for this block\n",
    "\n",
    "# g = rag.graph.copy()\n",
    "# regions = rag.edge_nodes.copy()\n",
    "# \n",
    "# while g.number_of_nodes() > 3:\n",
    "#     cheapest_edge_val = np.inf\n",
    "#     cheapest_edge = [0, 0]\n",
    "# \n",
    "#     for n1 in regions:\n",
    "#         for n2 in nx.all_neighbors(g, n1):\n",
    "#             dst = 15 * (g.nodes[n1]['mean depth'] - g.nodes[n2]['mean depth']) ** 2 + (g.nodes[n1]['pixel count'] + g.nodes[n2]['pixel count']) + g[n1][n2]['weight'] \n",
    "#             if dst < cheapest_edge_val:\n",
    "#                 cheapest_edge_val = dst\n",
    "#                 cheapest_edge = [n1, n2]\n",
    "# \n",
    "#     n1 = cheapest_edge[0]\n",
    "#     n2 = cheapest_edge[1]\n",
    "#     g.remove_edge(n1, n2)\n",
    "#     if n2 in regions:\n",
    "#         regions.remove(n2)\n",
    "# \n",
    "#     g.nodes[n1]['mask'] = np.logical_or(g.nodes[n1]['mask'], g.nodes[n2]['mask'])\n",
    "#     g.nodes[n1]['pixel count'] += g.nodes[n2]['pixel count']\n",
    "#     g.nodes[n1]['total color'] = np.append(g.nodes[n1]['total color'], g.nodes[n2]['total color'], axis=0)\n",
    "#     g.nodes[n1]['total depth'] = np.append(g.nodes[n1]['total depth'], g.nodes[n2]['total depth'], axis=0)\n",
    "#     g.nodes[n1]['mean color'] = np.sum(g.nodes[n1]['total color'] / g.nodes[n1]['pixel count'], axis=0)\n",
    "#     g.nodes[n1]['mean depth'] = np.sum(g.nodes[n1]['total depth'] / g.nodes[n1]['pixel count'], axis=0)\n",
    "#     \n",
    "#     n1_con = []\n",
    "#     for c in nx.all_neighbors(g, n1):\n",
    "#         n1_con.append(c)\n",
    "#     for c in n1_con:\n",
    "#         g.remove_edge(n1, c)\n",
    "# \n",
    "#     n2_con = []\n",
    "#     for c in nx.all_neighbors(g, n2):\n",
    "#         n2_con.append(c)\n",
    "#     for c in n2_con:\n",
    "#         g.remove_edge(n2, c)\n",
    "# \n",
    "#     for n in np.unique(n1_con + n2_con):\n",
    "#         g.add_edge(n1, n)\n",
    "#         g[n1][n]['weight'] = (\n",
    "#             color.deltaE_cie76(g.nodes[n1]['mean color'], g.nodes[n]['mean color'])\n",
    "#             # abs(g.nodes[x]['mean depth'] - g.nodes[y]['mean depth'])\n",
    "#         )\n",
    "# \n",
    "#     g.remove_node(n2)"
   ],
   "execution_count": 133,
   "outputs": []
  },
  {
   "cell_type": "code",
   "id": "f38a5566-c49a-4d2b-9f30-d401f747408d",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-05-23T16:36:43.932343Z",
     "start_time": "2024-05-23T16:36:43.924557Z"
    }
   },
   "source": [
    "# n, m = np.shape(depth)\n",
    "# \n",
    "# print(g)\n",
    "# print(regions)\n",
    "# \n",
    "# masks = []\n",
    "# \n",
    "# plt.figure(figsize=(16,10))\n",
    "# for i, reg in enumerate(regions):\n",
    "#     plt.subplot(221 + i)\n",
    "#     res = np.zeros((n, m, 3))\n",
    "#     res[g.nodes[reg]['mask']] = img[g.nodes[reg]['mask']]\n",
    "#     masks.append(g.nodes[reg]['mask'])\n",
    "#     plt.imshow(res)\n",
    "#     \n",
    "# # print(g.nodes[1]['mask'].shape)\n",
    "# # print(res.shape)"
   ],
   "execution_count": 134,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "id": "373c4ede-3bfa-4e18-8399-841dbdac6e32",
   "metadata": {},
   "source": [
    "# TODO: keep the most salient objects together\n",
    "# TODO: should attempt to push the depth amount to ensure that the different layers have significant enough difference in depth\n",
    "# TODO: create a conda or pip env\n",
    "# TODO: difference in superpixels should be more than just difference in average color and depth (could also consider difference in texture, saliency, and objects)\n",
    "\n",
    "what does the edge weight mean?\n",
    "- at the moment the edge weight is based on the difference in color and depth between superpixels\n",
    "- this doesn't really make sense because a single object could be made from many colors\n",
    "    - what if we used the information from the segment anything to get the objects then use superpixels to get a better outline\n",
    "    - perform segment anything then find all the superpixels that fit inside the segments\n",
    "    - then for superpixels within a segment make the weights large (and use medium weights for when the color changes but still within same segment)\n",
    "\n",
    "large weights for parts to slice or small weights for parts to slice\n",
    "- small weights for the parts to slice\n",
    "- large weights for parts to keep together\n",
    "    - or small weights for parts to keep together\n",
    "    - small difference in depth to keep together\n",
    "- small dist for depth and color to keep together (choose the smallest disparity value to add)\n",
    "\n",
    "how do we also consider the depth of the object?\n",
    "- consider 4 (or as many layers as we want) clouds that are initialized to the kmeans averages for depths over the entire image\n",
    "- begin by taking the 4 points next to the edge with the nearest depth values\n",
    "- then we continusouly merge adjacent superpixels based on edge weight (the difference in color and segment anything result) and the difference in average depth for that superpixel\n",
    "- each time we can update the average depth for our cloud as use that updated depth when looking for the next superpixel\n",
    "\n",
    "instead of initalizing only 4 clouds we can allow all the edge nodes to be clouds and iterate until there are only 4 left"
   ]
  },
  {
   "cell_type": "code",
   "id": "b533b310-a80e-43c6-a30f-108d36e73173",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-05-23T16:36:43.946735Z",
     "start_time": "2024-05-23T16:36:43.933470Z"
    }
   },
   "source": [
    "# from tunnel_book.saliency_map import FasaSaliencyMapping\n",
    "# import cv2"
   ],
   "execution_count": 135,
   "outputs": []
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-05-23T16:36:43.962424Z",
     "start_time": "2024-05-23T16:36:43.947775Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# my_map = FasaSaliencyMapping(img.shape[0], img.shape[1])  # init the saliency object\n",
    "# image_salient_1 = my_map.returnMask(color.rgb2lab(img), tot_bins=8, format='LAB')  # get the mask from the original image\n",
    "# image_salient_1 = cv2.GaussianBlur(image_salient_1, (3,3), 1)  # applying gaussin blur to make it pretty\n",
    "# \n",
    "# print(image_salient_1.shape)\n",
    "# plt.figure(figsize=(16,10))\n",
    "# # plt.imshow(image_salient_1 > 128)\n",
    "# plt.imshow(normalize_image(image_salient_1))\n",
    "# # plt.imshow(np.exp(-image_salient_1/256))\n",
    "# plt.colorbar()"
   ],
   "id": "cea7dc7f270fe7d0",
   "execution_count": 136,
   "outputs": []
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-05-23T16:36:43.975039Z",
     "start_time": "2024-05-23T16:36:43.963515Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# plt.figure(figsize=(16,10))\n",
    "# plt.imshow(color.label2rgb(rgb_slic, image_salient_1, kind='avg', bg_label=0))\n",
    "# plt.colorbar()"
   ],
   "id": "4509214fd4bae2e6",
   "execution_count": 137,
   "outputs": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python (tunnel book)",
   "language": "python",
   "name": "tunnel-book"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
